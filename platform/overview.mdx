---
title: 'Platform Overview'
description: 'What is Osmosis Platform and what can you do with it'
---

[Osmosis Platform](https://platform.osmosis.ai) is the central hub for managing reinforcement learning training of LLMs. It handles GPU provisioning, training orchestration, metrics collection, and model management — so you can focus on defining agent behavior and evaluation logic.

## Core Concepts

| Concept | Description |
|---------|-------------|
| **Workspace** | Top-level container for your team. Holds projects, members, API keys, and integrations. |
| **Project** | A training context within a workspace. Contains training runs, reward functions, tools, and datasets. |
| **Training Run** | A single RL training session. Configured with a base model, dataset, reward functions, and tools. |
| **Reward Function** | Python function that scores LLM outputs deterministically. Returns a float. |
| **Reward Rubric** | Natural language criteria evaluated by an LLM judge during training. |
| **MCP Tools** | Functions the agent can call during rollouts (calculators, search, code execution, etc.). |
| **Rollout Server** | An HTTP server you build that implements your custom agent loop. The training cluster sends rollout requests to your server, which orchestrates tool calls and LLM inference, then returns trajectories and rewards. Built with the Python SDK's `RolloutAgentLoop` API. |
| **Checkpoint** | A saved model state during training. Can be merged and exported to Hugging Face. |

## Architecture

Osmosis supports two rollout modes. **Choose one** depending on where you want the agent loop to run during training.

```mermaid
graph TD
    subgraph A["Option A — Local Rollout"]
        GR[GitHub Repo]
    end

    subgraph B["Option B — Remote Rollout"]
        RS[Your Rollout Server]
    end

    GR -- "Git Sync" --> P[Osmosis Platform]
    P -- "Sync rewards & tools" --> C

    RS <-- "HTTP API" --> C

    subgraph C["GPU Training Cluster"]
        RL[RL Training]
    end

    C --> M[Trained Model]
    M --> HF[Hugging Face Hub]
```

### Option A: Local Rollout

Agent loop runs **inside** the training cluster. Push reward functions, rubrics, and MCP tools to GitHub — the platform syncs and runs everything. No server to deploy.

### Option B: Remote Rollout

Agent loop runs on **your own server**. You only need to implement two functions — `get_tools()` (define available tools) and `run()` (agent loop logic) — by subclassing `RolloutAgentLoop`. The Python SDK automatically creates a trainer-compatible HTTP server that handles all protocol details (`/v1/rollout/init`, `/v1/chat/completions`, `/v1/rollout/completed`). Full control over agent logic and tool execution.

## Feature Summary

<CardGroup cols={2}>
  <Card title="Training Runs" icon="play" href="/platform/training-runs">
    Configure and launch RL training with custom models, datasets, and rewards.
  </Card>
  <Card title="Monitoring" icon="chart-line" href="/platform/monitoring">
    Real-time metrics, training logs, and checkpoint management.
  </Card>
  <Card title="GitHub Integration" icon="github" href="/platform/github-integration">
    Connect repositories for automatic sync of tools, rewards, and rubrics.
  </Card>
  <Card title="LLM Judges" icon="scale-balanced" href="/platform/llm-judges">
    Configure LLM providers for reward rubric evaluation.
  </Card>
  <Card title="Workspace & Team" icon="users" href="/platform/workspace-settings">
    Manage members, API keys, and integrations.
  </Card>
  <Card title="Getting Started" icon="rocket" href="/platform/quickstart">
    Sign up, create a project, and launch your first training run.
  </Card>
</CardGroup>

## Choose Your Workflow

<CardGroup cols={2}>
  <Card title="Local Rollout" icon="code-branch" href="/git-sync/overview">
    **Best for: reward functions, rubrics, and MCP tools**

    Define evaluation logic in your repository. Push to GitHub and Osmosis auto-syncs everything. No server to manage.
  </Card>
  <Card title="Remote Rollout" icon="server" href="/remote-rollout/overview">
    **Best for: custom agent loops with complex logic**

    Build an HTTP server implementing your agent loop. The training cluster connects to your server during rollouts.
  </Card>
</CardGroup>
